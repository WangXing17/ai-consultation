# RAG 用户提问优化方案

在基于 RAG 的医疗问答系统中，用户输入往往口语化、简短或模糊，直接用于检索会导致召回不准。对**用户提问进行优化**是提升检索与回答质量的常见手段。下面是业界成熟方案与在本项目中的推荐用法。

---

## 一、成熟方案概览

### 1. Query Rewriting（查询改写）

**思路**：用 LLM 把用户原问句改写成「更利于检索」的表述，再用改写后的 query 做向量/关键词检索。

- **适用**：口语化、指代不清、多轮中的省略句。
- **示例**：  
  - 用户：「我最近老疼」→ 改写：「头痛或身体疼痛的症状描述与可能原因」  
  - 用户：「这个药能跟酒一起吗？」+ 上文提到布洛芬 → 改写：「布洛芬与酒精同服的禁忌与风险」
- **注意**：改写后仍应用**原始问题**参与生成回答和缓存 key，避免答非所问和缓存错乱。

### 2. Query Expansion / 多查询扩展（Multi-Query）

**思路**：由 LLM 根据原问题生成 N 个语义相近或互补的查询，分别检索后合并、去重、重排。

- **适用**：一题多问法、同义表述多（如「发烧」vs「发热」）、提高召回多样性。
- **实现要点**：  
  - 原 query + 扩展 query 各自检索，结果按来源合并、去重。  
  - 可对「原 query 命中的文档」适当提权，减轻扩展 query 引入的噪声。  
- **成本**：检索次数增加（约 N 倍），需在召回质量和延迟/成本间权衡。

### 3. HyDE（Hypothetical Document Embeddings）

**思路**：不直接用问题向量检索，而是先用 LLM 根据问题生成若干段「假设性答案文档」，对这些假设文档做 embedding，用其向量（或平均向量）去检索真实文档。

- **适用**：领域专业、query 与文档表述差异大（如医学专业术语 vs 用户口语）。
- **优点**：query 与文档在「文档空间」对齐，检索更稳。  
- **注意**：需控制假设文档的幻觉（如限定领域、长度、条数），必要时只用 HyDE 做一路召回再与原始 query 召回融合。

### 4. 关键词提取 / 规范化（Keyword Extraction & Normalization）

**思路**：从用户问题中抽取医学术语、症状、部位、药物等关键词，再与知识库的标签/关键词/同义词表对齐（如「头疼」→「头痛」），用规范化后的词参与 BM25 或规则检索。

- **适用**：你已有 BM25 和规则召回（症状、疾病、药物等），能显著提升关键词召回率。
- **实现**：  
  - 规则/词典：同义词映射、症状标准化名称。  
  - 可选：小模型或 LLM 做「症状/疾病/药物」实体识别，再查表规范化。

### 5. 意图识别 + 分路由

**思路**：先判断用户意图（如「用药咨询 / 症状问诊 / 检查解读 / 紧急求助」），再根据意图选择不同检索策略或 prompt。

- **示例**：  
  - 识别为「紧急」→ 走急诊规则 + 高优先级检索 + 固定安全话术。  
  - 识别为「用药」→ 加强药物、禁忌、相互作用相关文档的权重或单独一路检索。
- **与现有逻辑结合**：你已有 `rule_based_search` 的「紧急」等规则，可把「意图」作为更上层的路由，再调现有多路召回。

### 6. 多轮上下文压缩（Contextual Compression）

**思路**：多轮对话时，把最近几轮 QA 压缩成一句「带上下文的单轮 query」，再去做检索与生成。

- **示例**：  
  - 历史：「我头痛」→「建议休息」；用户：「那要是还发烧呢？」  
  - 压缩 query：「头痛并伴有发烧时的处理建议」。  
- **注意**：压缩后的 query 仅用于检索；展示和生成仍用原始最后一问 + 历史。

---

## 二、在本项目中的推荐组合

结合你当前架构（**向量 + BM25 + 规则 + LLM 重排 + MCP 兜底**），推荐优先做两件事：

| 优先级 | 方案 | 作用 | 实现成本 |
|--------|------|------|----------|
| 高 | **Query Rewriting** | 口语→检索友好表述，提升向量/BM25 命中率 | 低：单次 LLM 调用 |
| 高 | **关键词规范化** | 与现有 BM25/规则词表对齐（如「头疼」→「头痛」） | 低：词典 + 简单替换或小模型 |
| 中 | **多查询扩展（N=2）** | 同义扩展，提高召回多样性 | 中：多一路检索 + 合并去重 |
| 中 | **HyDE 一路召回** | 专业领域 query 与文档对齐 | 中：多一路向量检索 |
| 低 | **意图分路由** | 紧急/用药等差异化策略 | 中：意图模型或规则 + 分支 |

建议实施顺序：

1. **先上 Query Rewriting**：只改「用于检索的 query」，回答与缓存仍用原始 `request.question`，风险小、收益明显。  
2. **再加关键词规范化**：对改写后的 query（或原 query）做同义词/症状名规范化，再喂给 BM25 和规则召回。  
3. 若仍有个别场景召回不足，再考虑 **Multi-Query（2 个扩展 query）** 或 **HyDE 一路**。

---

## 三、实现要点（与现有代码的关系）

- **缓存 key**：必须继续用**原始问题**（及 `user_id`）生成，避免同一用户同一问因改写不同而缓存失效或重复缓存。  
- **检索**：向量检索、BM25、规则召回、MCP 兜底，均使用**优化后的 query**（改写 + 可选规范化）。  
- **生成**：`build_prompt` 中「用户问题」仍用**原始问题**，保证回答针对用户原意。  
- **可配置**：通过配置或环境变量开关「是否启用改写 / 多查询 / HyDE」，便于 A/B 与降级。

---

## 四、参考文献与延伸阅读

- Query Rewriting：多篇 2024 CCL/ACL 工作显示，BM25 + ChatGPT 改写 + 融合打分可显著提升 nDCG@10。  
- HyDE：*Precise Zero-Shot Dense Retrieval without Relevance Labels*（HyDE 原论文）；各 RAG 框架（如 LangChain、Haystack）均有 HyDE 组件。  
- 多查询扩展：LangChain 的 `MultiQueryRetriever` 等。

以上方案可根据业务指标（召回率、首条准确率、延迟）逐步叠加与调参。

---

## 五、本项目已实现

- **模块**：`rag/query_optimizer.py`  
  - `optimize(question, history, enable_rewrite=..., enable_normalize=...)`：统一入口，返回用于检索的 query。  
  - **Query Rewriting**：LLM 将口语/指代改写成一句检索用问句（结合 `history` 补全指代）。  
  - **关键词规范化**：内置医疗同义词表（如「头疼」→「头痛」、「拉肚子」→「腹泻」），对 BM25/规则召回更友好。

- **配置**（`config.py` / 环境变量）：  
  - `ENABLE_QUERY_REWRITE`：是否启用 LLM 改写，默认 `true`。  
  - `ENABLE_QUERY_NORMALIZE`：是否启用关键词规范化，默认 `true`。

- **调用位置**（`main.py`）：  
  - 在 `stream_response` 与 `consult` 中，先用 `optimize_query(...)` 得到 `retrieval_query`，再用其做 `retriever.retrieve()` 与 MCP 兜底；  
  - `build_prompt` 与缓存 key 仍使用**原始** `request.question`，保证回答针对用户原意且缓存正确。

关闭改写或规范化时，在 `.env` 中设置例如：  
`ENABLE_QUERY_REWRITE=false` 或 `ENABLE_QUERY_NORMALIZE=false`。
